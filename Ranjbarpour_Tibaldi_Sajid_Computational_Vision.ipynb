{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9dJ8we9uZl5"
   },
   "outputs": [],
   "source": [
    "# Arezou Ranjbarpour Maralani\n",
    "# Lorenzo Tibaldi\n",
    "# Momina Sajid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xlXlB8CUurrw",
    "outputId": "a4d4dd80-deb3-42fa-c9cb-5142a8914f6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Data manipulation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#Model creation\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Input, Dropout, BatchNormalization\n",
    "\n",
    "#Files management\n",
    "import os\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6OzP6dpruf9"
   },
   "outputs": [],
   "source": [
    "#Plots accuracy and loss for train and validation sets of a trained model\n",
    "def plot_history(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sN8ty9m3382j"
   },
   "outputs": [],
   "source": [
    "#Data upload\n",
    "#When the file selection pops up, you should select a zip file containing the data\n",
    "files.upload()\n",
    "for i in os.listdir():\n",
    "    if i[0:2] == \"CV\":\n",
    "        !unzip \"$i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZCDn5aaAo2o"
   },
   "outputs": [],
   "source": [
    "#Creation of training, validation and test sets\n",
    "train_X = []\n",
    "train_Y = []\n",
    "\n",
    "test_X = []\n",
    "test_Y = []\n",
    "\n",
    "data = [\"seg_train\",\"seg_test\"]\n",
    "Ts = [train_X,test_X,train_Y,test_Y]\n",
    "for i,d in enumerate(data):\n",
    "    lbl = -1\n",
    "    for j in os.listdir(d):\n",
    "        #print(j)\n",
    "        lbl += 1\n",
    "        for n in os.listdir(os.path.join(d,j)):\n",
    "            \n",
    "            img = np.asarray(Image.open(os.path.join(d,j,n)).resize((200,200),Image.ANTIALIAS))\n",
    "            Ts[i].append(img)\n",
    "            #print(np.shape(Ts[i]),n)\n",
    "            Ts[i+2].append(lbl)\n",
    "        \n",
    "num_classes = lbl + 1\n",
    "\n",
    "Train_X = np.array(train_X)\n",
    "train_Y = np.array(train_Y)\n",
    "Test_X = np.array(test_X)\n",
    "test_Y = np.array(test_Y)\n",
    "\n",
    "Train_X, Val_X, train_Y, val_Y = train_test_split(Train_X, train_Y, test_size=0.3, random_state=7)\n",
    "\n",
    "input_size = np.shape(Test_X)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSvAJ9CHbVp5"
   },
   "outputs": [],
   "source": [
    "#Plot of an image in the training set\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(train_Y[77])\n",
    "plt.imshow(Train_X[77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpLMR3741-TG"
   },
   "outputs": [],
   "source": [
    "#Loading Xception and prepares the model with and without fine tuning\n",
    "train_X = applications.xception.preprocess_input(Train_X)\n",
    "val_X = applications.xception.preprocess_input(Val_X)\n",
    "test_X = applications.xception.preprocess_input(Test_X)\n",
    "\n",
    "premodel = applications.Xception(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
    "\n",
    "\n",
    "for layer in premodel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(premodel.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation=\"relu\")(x)\n",
    "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
    "\n",
    "finemodel.compile(keras.optimizers.Adam(), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])\n",
    "finemodel.fit(train_X, train_Y, batch_size=154, epochs = 16, validation_data=(val_X, val_Y), verbose = 0)\n",
    "\n",
    "for layer in finemodel.layers[-9:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lW0Fhddqu6SQ"
   },
   "outputs": [],
   "source": [
    "#Loading ResNet50V2 and prepares the model with and without fine tuning\n",
    "train_X = applications.resnet_v2.preprocess_input(Train_X)\n",
    "val_X = applications.resnet_v2.preprocess_input(Val_X)\n",
    "test_X = applications.resnet_v2.preprocess_input(Test_X)\n",
    "\n",
    "premodel = applications.ResNet50V2(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
    "\n",
    "\n",
    "for layer in premodel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(premodel.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation=\"relu\")(x)\n",
    "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
    "\n",
    "finemodel.compile(keras.optimizers.Adam(), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])\n",
    "finemodel.fit(train_X, train_Y, batch_size=154, epochs = 16, validation_data=(val_X, val_Y), verbose = 0)\n",
    "\n",
    "for layer in finemodel.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w45y4APayhhU"
   },
   "outputs": [],
   "source": [
    "#Loading InceptionV3 and prepares the model with and without fine tuning\n",
    "train_X = applications.inception_v3.preprocess_input(Train_X)\n",
    "val_X = applications.inception_v3.preprocess_input(Val_X)\n",
    "test_X = applications.inception_v3.preprocess_input(Test_X)\n",
    "\n",
    "premodel = applications.InceptionV3(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
    "\n",
    "\n",
    "for layer in premodel.layers:\n",
    "    if layer.name[:5] != \"batch\":\n",
    "        layer.trainable = False\n",
    "\n",
    "x = Flatten()(premodel.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation=\"relu\")(x)\n",
    "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
    "\n",
    "\n",
    "for layer in finemodel.layers[-18:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "RpkX9wdjyTpv",
    "outputId": "4b9c6ea9-87e7-4e53-dcab-14709b469d87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "#Loading MobileNetV2 and prepares the model with and without fine tuning\n",
    "train_X = applications.mobilenet_v2.preprocess_input(Train_X)\n",
    "val_X = applications.mobilenet_v2.preprocess_input(Val_X)\n",
    "test_X = applications.mobilenet_v2.preprocess_input(Test_X)\n",
    "\n",
    "premodel = applications.MobileNetV2(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
    "\n",
    "\n",
    "for layer in premodel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(premodel.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation=\"relu\")(x)\n",
    "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
    "\n",
    "\n",
    "for layer in finemodel.layers[-9:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyjtwzm-yUgF"
   },
   "outputs": [],
   "source": [
    "#Loading DenseNet201 and prepares the model with and without fine tuning\n",
    "train_X = applications.densenet.preprocess_input(Train_X)\n",
    "val_X = applications.densenet.preprocess_input(Val_X)\n",
    "test_X = applications.densenet.preprocess_input(Test_X)\n",
    "\n",
    "premodel = applications.DenseNet201(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
    "\n",
    "\n",
    "for layer in premodel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(premodel.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation=\"relu\")(x)\n",
    "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
    "\n",
    "\n",
    "for layer in finemodel.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "92-zIO9pR8XT",
    "outputId": "851c4df1-1f51-45a0-e8a6-c630e4abb805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1540/1540 [==============================] - 16s 10ms/step\n",
      "660/660 [==============================] - 10s 15ms/step\n",
      "600/600 [==============================] - 6s 11ms/step\n",
      "CPU times: user 19.6 s, sys: 12.8 s, total: 32.4 s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Predicting the features using the selected model\n",
    "F_train = premodel.predict(train_X,batch_size=256, verbose=1)\n",
    "F_val =  premodel.predict(val_X,batch_size=111, verbose=1)\n",
    "F_test = premodel.predict(test_X,batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TudobCikxXZb"
   },
   "outputs": [],
   "source": [
    "#Definition of the top model, the classifier\n",
    "mainmodel = Sequential()\n",
    "mainmodel.add(Flatten(input_shape = np.shape(premodel.output)[1:]))\n",
    "mainmodel.add(BatchNormalization())\n",
    "mainmodel.add(Dense(512, activation=\"relu\"))\n",
    "mainmodel.add(Dropout(0.5))\n",
    "mainmodel.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "mainmodel.compile(keras.optimizers.Adam(), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "id": "db32yx7vd0Os",
    "outputId": "41aa6d29-abf0-4314-cfdb-bb63086901e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1540 samples, validate on 660 samples\n",
      "Epoch 1/16\n",
      "1540/1540 [==============================] - 1s 542us/step - loss: 0.3372 - accuracy: 0.9058 - val_loss: 0.1329 - val_accuracy: 0.9879\n",
      "Epoch 2/16\n",
      "1540/1540 [==============================] - 1s 409us/step - loss: 0.1470 - accuracy: 0.9948 - val_loss: 0.1390 - val_accuracy: 0.9909\n",
      "Epoch 3/16\n",
      "1540/1540 [==============================] - 1s 414us/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.1533 - val_accuracy: 0.9939\n",
      "Epoch 4/16\n",
      "1540/1540 [==============================] - 1s 408us/step - loss: 0.0257 - accuracy: 0.9974 - val_loss: 0.1012 - val_accuracy: 0.9970\n",
      "Epoch 5/16\n",
      "1540/1540 [==============================] - 1s 410us/step - loss: 0.0147 - accuracy: 0.9987 - val_loss: 0.3538 - val_accuracy: 0.9939\n",
      "Epoch 6/16\n",
      "1540/1540 [==============================] - 1s 407us/step - loss: 0.0542 - accuracy: 0.9981 - val_loss: 0.5405 - val_accuracy: 0.9939\n",
      "Epoch 7/16\n",
      "1540/1540 [==============================] - 1s 409us/step - loss: 5.3642e-08 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 0.9939\n",
      "Epoch 8/16\n",
      "1540/1540 [==============================] - 1s 405us/step - loss: 0.0275 - accuracy: 0.9987 - val_loss: 0.5919 - val_accuracy: 0.9939\n",
      "Epoch 9/16\n",
      "1540/1540 [==============================] - 1s 409us/step - loss: 0.0378 - accuracy: 0.9994 - val_loss: 0.6757 - val_accuracy: 0.9939\n",
      "Epoch 10/16\n",
      "1540/1540 [==============================] - 1s 410us/step - loss: 8.7311e-08 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.9939\n",
      "Epoch 11/16\n",
      "1540/1540 [==============================] - 1s 413us/step - loss: 5.3577e-05 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.9939\n",
      "Epoch 12/16\n",
      "1540/1540 [==============================] - 1s 418us/step - loss: 3.5608e-09 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.9939\n",
      "Epoch 13/16\n",
      "1540/1540 [==============================] - 1s 416us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6877 - val_accuracy: 0.9939\n",
      "Epoch 14/16\n",
      "1540/1540 [==============================] - 1s 414us/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.6062 - val_accuracy: 0.9924\n",
      "Epoch 15/16\n",
      "1540/1540 [==============================] - 1s 410us/step - loss: 5.8056e-09 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.9924\n",
      "Epoch 16/16\n",
      "1540/1540 [==============================] - 1s 411us/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.6176 - val_accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "#Train on the Intermediate features predicted before\n",
    "history = mainmodel.fit(F_train, train_Y, batch_size=154, epochs = 16, validation_data=(F_val, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpOUzPBmr49K"
   },
   "outputs": [],
   "source": [
    "#Plot of the training, accuracy and loss\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5BoeLWUPtyK"
   },
   "outputs": [],
   "source": [
    "#Evaluation on the test set\n",
    "mainmodel.evaluate(F_test, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "klt9Qs9qu11K"
   },
   "outputs": [],
   "source": [
    "#Training taking the images as input and classifing them with the fine tuned model\n",
    "finehistory = finemodel.fit(train_X, train_Y, batch_size=154, epochs = 16, validation_data=(val_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2GVjOE2vURo"
   },
   "outputs": [],
   "source": [
    "#Plot the history of the fine tuned model\n",
    "plot_history(finehistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyJh4PsmvWvr"
   },
   "outputs": [],
   "source": [
    "#Evaluation on the test set\n",
    "finemodel.evaluate(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lZKRO3FMWp2s",
    "outputId": "afa803ea-e10e-442d-df46-2c4a3cece286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1540, 100352) (660, 100352) (600, 100352)\n",
      "(2800, 100352) (2800,)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing for the dimensionality reduction algorithms\n",
    "Fr_train = F_train.reshape(np.shape(F_train)[0],-1)\n",
    "Fr_val = F_val.reshape(np.shape(F_val)[0],-1)\n",
    "Fr_test = F_test.reshape(np.shape(F_test)[0],-1)\n",
    "print(Fr_train.shape,Fr_val.shape,Fr_test.shape)\n",
    "\n",
    "features = np.array([*Fr_train, *Fr_val, *Fr_test])\n",
    "labels = np.array([*train_Y, *val_Y, *test_Y])\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXxXvhbvzBVa"
   },
   "outputs": [],
   "source": [
    "#How many dimensions? we selected 3 for a 3D view\n",
    "dimensionality = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "HCCRfEY1CBJk",
    "outputId": "53e20ef3-4029-404e-9efb-5b7deb05f00b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 786 ms, total: 19.5 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Reduction by PCA\n",
    "F3D = PCA(dimensionality).fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "TILO6707mOJH",
    "outputId": "efcdaff7-4a45-495b-b44d-ba783687bc4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 16s, sys: 3.25 s, total: 26min 20s\n",
      "Wall time: 25min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Reduction by T-SNE\n",
    "f3d = TSNE(dimensionality).fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9lN_TRQ8boR"
   },
   "outputs": [],
   "source": [
    "#Save the npy for the post visualization\n",
    "np.save(\"PCA.npy\", F3D)\n",
    "np.save(\"TSNE.npy\", f3d)\n",
    "np.save(\"labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "oXVAmVGUtTvU",
    "outputId": "9f75e470-0489-46fb-c286-ef2c410e655e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA silhouette score: 0.6580159\n",
      "TSNE silhouette score: 0.4279452\n"
     ]
    }
   ],
   "source": [
    "#Silhouette score calculation \n",
    "print(\"PCA silhouette score:\",silhouette_score(F3D,labels))\n",
    "print(\"TSNE silhouette score:\",silhouette_score(f3d,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiuiIRivbhaE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Ranjbarpour_Tibaldi_Sajid_Computational_Vision.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
